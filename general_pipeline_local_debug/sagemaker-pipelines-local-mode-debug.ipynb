{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use SageMaker Pipelines to Run and Debug Your Jobs Locally\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latest notebook version: https://github.com/aws-samples/amazon-sagemaker-local-mode/blob/main/general_pipeline_local_debug/sagemaker-pipelines-local-mode-debug.ipynb (pipeline modified from [here](https://github.com/aws/amazon-sagemaker-examples/blob/main/sagemaker-pipelines/tabular/local-mode/sagemaker-pipelines-local-mode.ipynb))\n",
    "\n",
    "Blog: [Debugging Python Code in Amazon SageMaker Locally Using Visual Studio Code and PyCharm: A Step-by-Step Guide](https://dev.to/arlind0xbb/debugging-python-code-in-amazon-sagemaker-locally-using-visual-studio-code-and-pycharm-a-step-by-step-guide-2cbc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to orchestrate SageMaker jobs locally using SageMaker Pipelines. \n",
    "It also contains the code snippets to show how to debug with VS Code or PyCharm Professional.\n",
    "\n",
    "The notebook uses a parameter `run_locally` to define the `pipeline_session` to either be a `LocalPipelineSession` object or a `PipelineSession` object.\n",
    "Depending on how the `run_locally` parameter is set, the pipeline will run on your local machine or in the cloud. \n",
    "\n",
    "**Note**: You can run this on SageMaker Classic Notebook instances OR your local IDE.\n",
    "This notebook will also run in the new SageMaker Studio (e.g. Code Editor or Jupyterlab). It will not run in SageMaker Studio Classic since the classic does not support docker."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites for Sagemaker Studio (Code Editor or Jupyterlab)\n",
    "\n",
    "To run this notebook in the new Sagemaker Studio Experience (e.g. Code Editor or Jupyterlab), you need to install Docker as described in the  [Local mode support in Amazon SageMaker Studio docs](https://docs.aws.amazon.com/sagemaker/latest/dg/studio-updated-local.html)\n",
    "\n",
    "### Enable Docker in Sagemaker Studio Domain\n",
    "\n",
    "Open e.g. AWS CloudShell and update the domain to enable docker access.\n",
    "\n",
    "```sh\n",
    "# update domain\n",
    "aws --region region \\\n",
    "    sagemaker update-domain --domain-id domain-id \\\n",
    "    --domain-settings-for-update '{\"DockerSettings\": {\"EnableDockerAccess\": \"ENABLED\"}}'\n",
    "```\n",
    "\n",
    "Open the terminal in e.g. Code Editor and run the following steps to add docker.\n",
    "\n",
    "### Add apt repos for docker\n",
    "\n",
    "```sh\n",
    "# Add Docker's official GPG key:\n",
    "sudo apt-get update\n",
    "sudo apt-get install ca-certificates curl gnupg\n",
    "sudo install -m 0755 -d /etc/apt/keyrings\n",
    "curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n",
    "sudo chmod a+r /etc/apt/keyrings/docker.gpg\n",
    "\n",
    "### Add the repository to Apt sources:\n",
    "echo \\\n",
    "  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n",
    "  $(. /etc/os-release && echo \"$VERSION_CODENAME\") stable\" | \\\n",
    "  sudo tee /etc/apt/sources.list.d/docker.list > /dev/null\n",
    "sudo apt-get update\n",
    "```\n",
    "\n",
    "### Install docker packages\n",
    "```sh\n",
    "VERSION_STRING=5:20.10.24~3-0~ubuntu-jammy\n",
    "sudo apt-get install docker-ce-cli=$VERSION_STRING docker-buildx-plugin docker-compose-plugin\n",
    "```\n",
    "\n",
    "### Run sample container\n",
    "\n",
    "```sh\n",
    "docker run --network=sagemaker hello-world\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging python code in Sagemaker Studio and LocalMode\n",
    "\n",
    "Make sure to read the blog about [Debugging Python Code in Amazon SageMaker Locally Using Visual Studio Code and PyCharm: A Step-by-Step Guide](https://dev.to/arlind0xbb/debugging-python-code-in-amazon-sagemaker-locally-using-visual-studio-code-and-pycharm-a-step-by-step-guide-2cbc)\n",
    "\n",
    "You can use pathMappings to allow vscode to find the source code file locally when debugging:\n",
    "\n",
    "```json\n",
    "{\n",
    "    // Use IntelliSense to learn about possible attributes.\n",
    "    // Hover to view descriptions of existing attributes.\n",
    "    // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387\n",
    "    \"version\": \"0.2.0\",\n",
    "    \"configurations\": [\n",
    "        {\n",
    "            \"name\": \"Python: Remote Attach\",\n",
    "            \"type\": \"python\",\n",
    "            \"request\": \"attach\",\n",
    "            \"connect\": {\n",
    "                \"host\": \"localhost\",\n",
    "                \"port\": 5678\n",
    "            },\n",
    "            \"pathMappings\": [\n",
    "                {\n",
    "                    \"localRoot\": \"${workspaceFolder}/general_pipeline_local_debug/code\",\n",
    "                    \"remoteRoot\": \"/opt/ml/processing/input/code/\"\n",
    "                }\n",
    "            ],\n",
    "            \"justMyCode\": true\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SageMaker Pipelines Local Mode\n",
    "\n",
    "SageMaker Pipelines Local Mode supports the following activities, which are demonstrated in this notebook:\n",
    "\n",
    "* ProcessingStep\n",
    "* TrainingStep\n",
    "* ConditionStep\n",
    "* ModelStep\n",
    "* TransformStep\n",
    "* FailStep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset you use is the [UCI Machine Learning Abalone Dataset](https://archive.ics.uci.edu/ml/datasets/abalone) [1].  The aim for this task is to determine the age of an abalone snail from its physical measurements. At the core, this is a regression problem.\n",
    "\n",
    "The dataset contains several features: length (the longest shell measurement), diameter (the diameter perpendicular to length), height (the height with meat in the shell), whole_weight (the weight of whole abalone), shucked_weight (the weight of meat), viscera_weight (the gut weight after bleeding), shell_weight (the weight after being dried), sex ('M', 'F', 'I' where 'I' is Infant), and rings (integer).\n",
    "\n",
    "The number of rings turns out to be a good approximation for age (age is rings + 1.5). However, to obtain this number requires cutting the shell through the cone, staining the section, and counting the number of rings through a microscope, which is a time-consuming task. However, the other physical measurements are easier to determine. You use the dataset to build a predictive model of the variable rings through these other physical measurements.\n",
    "\n",
    "Before you upload the data to an S3 bucket, install the SageMaker Python SDK and gather some constants you can use later in this notebook.\n",
    "\n",
    "> [1] Dua, D. and Graff, C. (2019). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Install the latest version of the SageMaker Python SDK. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install 'sagemaker' --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os\n",
    "# make sure you have your aws credentials set up\n",
    "# setup the right aws profile (if required)\n",
    "profile_name=None\n",
    "#profile_name = 'your-aws-profile'\n",
    "if not profile_name: \n",
    "    boto3.setup_default_session(profile_name=profile_name)\n",
    "    session = boto3.Session(profile_name=profile_name)\n",
    "else:\n",
    "    session = boto3.Session()\n",
    "# define your default sagemaker execution role\n",
    "default_sagemaker_execution_role = \"AmazonSageMaker-ExecutionRole-20220610T143720\"\n",
    "\n",
    "run_locally = True \n",
    "\n",
    "# os.environ[\"AWS_DEFAULT_REGION\"]=\"us-east-1\"\n",
    "#caller_identity = boto3.client('sts').get_caller_identity()\n",
    "#print(caller_identity) # show the current aws role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker.workflow.pipeline_context import LocalPipelineSession\n",
    "from sagemaker.workflow.pipeline_context import PipelineSession\n",
    "\n",
    "# Create a `LocalPipelineSession` object so that each pipeline step will run locally\n",
    "# To run this pipeline in the cloud, you must change `LocalPipelineSession()` to `PipelineSession()`\n",
    "if run_locally:\n",
    "    pipeline_session = LocalPipelineSession(boto_session = session)\n",
    "    s3_prefix = \"sm-pipelines-local-mode-example\"\n",
    "    pipeline_name = f\"LocalModePipeline\"\n",
    "else: \n",
    "    pipeline_session = PipelineSession()\n",
    "    s3_prefix = \"sm-pipelines-remote-mode-example\"\n",
    "    pipeline_name = f\"LocalModePipeline-SM\"\n",
    "    \n",
    "region = pipeline_session.boto_region_name\n",
    "default_bucket = pipeline_session.default_bucket()\n",
    "\n",
    "role = None  # Role is set below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Sagemaker Execution Role\n",
    "\n",
    "For simplicity, we will use the provided Sagemaker execution role not only when running in the cloud, but also when running locally. Note that you can also use another role when running locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# role = sagemaker.get_execution_role() # this will give the current role of the notebook, and not necessary the Sagemaker execution role. The Sagemaker execution role is only required when running in the cloud\n",
    "iam = boto3.client('iam')\n",
    "role = iam.get_role(RoleName=default_sagemaker_execution_role)['Role']['Arn'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, upload the data into the default bucket. You can select our own data set for the `input_data_uri` as is appropriate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull the dataset from SageMaker's public S3 bucket and upload it to your own S3 bucket\n",
    "\n",
    "local_path = \"data/abalone-dataset.csv\"\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(f\"sagemaker-example-files-prod-{region}\").download_file(\n",
    "    \"datasets/tabular/uci_abalone/abalone.csv\", local_path\n",
    ")\n",
    "\n",
    "base_uri = f\"s3://{default_bucket}/{s3_prefix}/abalone-data-set\"\n",
    "input_data_uri = sagemaker.s3.S3Uploader.upload(\n",
    "    local_path=local_path,\n",
    "    desired_s3_uri=base_uri,\n",
    ")\n",
    "print(input_data_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterString, ParameterFloat\n",
    "\n",
    "processing_instance_count = 1\n",
    "training_instance_count = 1\n",
    "transform_instance_count = 1\n",
    "instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "input_data = ParameterString(\n",
    "    name=\"InputData\",\n",
    "    default_value=input_data_uri,\n",
    ")\n",
    "\n",
    "mse_threshold = ParameterFloat(name=\"MseThreshold\", default_value=7.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Processing Step for Feature Engineering\n",
    "\n",
    "First, develop a preprocessing script that is specified in the Processing step.\n",
    "\n",
    "This notebook cell writes a file `preprocessing_abalone.py`, which contains the preprocessing script. You can update the script, and rerun this cell to overwrite. The preprocessing script uses `scikit-learn` to do the following:\n",
    "\n",
    "* Fill in missing sex category data and encode it so that it is suitable for training.\n",
    "* Scale and normalize all numerical fields, aside from sex and rings numerical data.\n",
    "* Split the data into training, validation, and test datasets.\n",
    "\n",
    "The Processing step executes the script on the input data. The Training step uses the preprocessed training features and labels to train a model. The Evaluation step uses the trained model and preprocessed test features and labels to evaluate the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/preprocessing.py\n",
    "import argparse\n",
    "import os\n",
    "import requests\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# # For vscode debugging\n",
    "# # Enable debugging with debugby\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"debugpy\"])\n",
    "subprocess.check_call([sys.executable, \"-m\", \"pip\", \"uninstall\", \"-y\", \"typing\"]) # required only for this specific scikit container to avoid package conflict\n",
    "import debugpy\n",
    "debugpy.listen((\"0.0.0.0\",5678))\n",
    "debugpy.wait_for_client()  # blocks execution until client is attached\n",
    "breakpoint()\n",
    "\n",
    "# # For PyCharm debugging\n",
    "# subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"pydevd-pycharm~=232.10203.26\"])\n",
    "# import pydevd_pycharm\n",
    "# pydevd_pycharm.settrace('host.docker.internal', port=8200, stdoutToServer=True, stderrToServer=True) # host.docker.internal to route from container to your host\n",
    "# breakpoint()\n",
    "\n",
    "# Since we get a headerless CSV file, we specify the column names here.\n",
    "feature_columns_names = [\n",
    "    \"sex\",\n",
    "    \"length\",\n",
    "    \"diameter\",\n",
    "    \"height\",\n",
    "    \"whole_weight\",\n",
    "    \"shucked_weight\",\n",
    "    \"viscera_weight\",\n",
    "    \"shell_weight\",\n",
    "]\n",
    "label_column = \"rings\"\n",
    "\n",
    "feature_columns_dtype = {\n",
    "    \"sex\": str,\n",
    "    \"length\": np.float64,\n",
    "    \"diameter\": np.float64,\n",
    "    \"height\": np.float64,\n",
    "    \"whole_weight\": np.float64,\n",
    "    \"shucked_weight\": np.float64,\n",
    "    \"viscera_weight\": np.float64,\n",
    "    \"shell_weight\": np.float64,\n",
    "}\n",
    "label_column_dtype = {\"rings\": np.float64}\n",
    "\n",
    "\n",
    "def merge_two_dicts(x, y):\n",
    "    z = x.copy()\n",
    "    z.update(y)\n",
    "    return z\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    base_dir = \"/opt/ml/processing\"\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        f\"{base_dir}/input/abalone-dataset.csv\",\n",
    "        header=None,\n",
    "        names=feature_columns_names + [label_column],\n",
    "        dtype=merge_two_dicts(feature_columns_dtype, label_column_dtype),\n",
    "    )\n",
    "    numeric_features = list(feature_columns_names)\n",
    "    numeric_features.remove(\"sex\")\n",
    "    numeric_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "            (\"scaler\", StandardScaler()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    categorical_features = [\"sex\"]\n",
    "    categorical_transformer = Pipeline(\n",
    "        steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"constant\", fill_value=\"missing\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preprocess = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", numeric_transformer, numeric_features),\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    y = df.pop(\"rings\")\n",
    "    X_pre = preprocess.fit_transform(df)\n",
    "    y_pre = y.to_numpy().reshape(len(y), 1)\n",
    "\n",
    "    X = np.concatenate((y_pre, X_pre), axis=1)\n",
    "\n",
    "    np.random.shuffle(X)\n",
    "    train, validation, test = np.split(X, [int(0.7 * len(X)), int(0.85 * len(X))])\n",
    "\n",
    "    pd.DataFrame(train).to_csv(f\"{base_dir}/train/train.csv\", header=False, index=False)\n",
    "    pd.DataFrame(validation).to_csv(\n",
    "        f\"{base_dir}/validation/validation.csv\", header=False, index=False\n",
    "    )\n",
    "    pd.DataFrame(test).to_csv(f\"{base_dir}/test/test.csv\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an instance of a `SKLearnProcessor` processor and use that in our `ProcessingStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "\n",
    "framework_version = \"1.2-1\"\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(\n",
    "    framework_version=framework_version,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"sklearn-abalone-process\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we take the output of the processor's `run` method and pass that as arguments to the `ProcessingStep`. By passing the `local_pipeline_session` to the `sagemaker_session`, calling `.run()` does not launch the processing job, it returns the arguments needed to run the job as a step in the pipeline.\n",
    "\n",
    "Note the `\"train_data\"` and `\"test_data\"` named channels specified in the output configuration for the processing job. Step `Properties` can be used in subsequent steps and resolve to their runtime values at execution. Specifically, this usage is called out when you define the training step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "processor_args = sklearn_processor.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(source=input_data, destination=\"/opt/ml/processing/input\"),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"train\", source=\"/opt/ml/processing/train\"),\n",
    "        ProcessingOutput(output_name=\"validation\", source=\"/opt/ml/processing/validation\"),\n",
    "        ProcessingOutput(output_name=\"test\", source=\"/opt/ml/processing/test\"),\n",
    "    ],\n",
    "    code=\"code/preprocessing.py\",\n",
    ")\n",
    "\n",
    "step_process = ProcessingStep(name=\"AbaloneProcess\", step_args=processor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/abalone.py\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import pathlib\n",
    "import pickle as pkl\n",
    "import tarfile\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "TRAIN_VALIDATION_FRACTION = 0.2\n",
    "RANDOM_STATE_SAMPLING = 200\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def prepare_data(train_dir, validation_dir):\n",
    "    \"\"\"Read data from train and validation channel, and return predicting features and target variables.\n",
    "\n",
    "    Args:\n",
    "        data_dir (str): directory which saves the training data.\n",
    "\n",
    "    Returns:\n",
    "        Tuple of training features, training target, validation features, validation target.\n",
    "    \"\"\"\n",
    "    df_train = pd.read_csv(\n",
    "        os.path.join(train_dir, \"train.csv\"),\n",
    "        header=None,\n",
    "    )\n",
    "    df_train = df_train.iloc[np.random.permutation(len(df_train))]\n",
    "    df_train.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df_train.shape[1] - 1)]\n",
    "\n",
    "    try:\n",
    "        df_validation = pd.read_csv(\n",
    "            os.path.join(validation_dir, \"validation.csv\"),\n",
    "            header=None,\n",
    "        )\n",
    "        df_validation.columns = [\"target\"] + [\n",
    "            f\"feature_{x}\" for x in range(df_validation.shape[1] - 1)\n",
    "        ]\n",
    "\n",
    "    except FileNotFoundError:  # when validation data is not available in the directory\n",
    "        logging.info(\n",
    "            f\"Validation data is not found. {TRAIN_VALIDATION_FRACTION * 100}% of training data is \"\n",
    "            f\"randomly selected as validation data. The seed for random sampling is {RANDOM_STATE_SAMPLING}.\"\n",
    "        )\n",
    "        df_validation = df_train.sample(\n",
    "            frac=TRAIN_VALIDATION_FRACTION,\n",
    "            random_state=RANDOM_STATE_SAMPLING,\n",
    "        )\n",
    "        df_train.drop(df_validation.index, inplace=True)\n",
    "        df_validation.reset_index(drop=True, inplace=True)\n",
    "        df_train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    X_train, y_train = df_train.iloc[:, 1:], df_train.iloc[:, :1]\n",
    "    X_val, y_val = df_validation.iloc[:, 1:], df_validation.iloc[:, :1]\n",
    "\n",
    "    return X_train.values, y_train.values, X_val.values, y_val.values\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Run training.\"\"\"\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--max_depth\",\n",
    "        type=int,\n",
    "    )\n",
    "    parser.add_argument(\"--eta\", type=float)\n",
    "    parser.add_argument(\"--gamma\", type=int)\n",
    "    parser.add_argument(\"--min_child_weight\", type=int)\n",
    "    parser.add_argument(\"--subsample\", type=float)\n",
    "    parser.add_argument(\"--verbosity\", type=int)\n",
    "    parser.add_argument(\"--objective\", type=str)\n",
    "    parser.add_argument(\"--num_round\", type=int)\n",
    "    parser.add_argument(\"--tree_method\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--predictor\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--learning_rate\", type=str, default=\"auto\")\n",
    "    parser.add_argument(\"--output_data_dir\", type=str, default=os.environ.get(\"SM_OUTPUT_DATA_DIR\"))\n",
    "    parser.add_argument(\"--model_dir\", type=str, default=os.environ.get(\"SM_MODEL_DIR\"))\n",
    "    parser.add_argument(\"--train\", type=str, default=os.environ.get(\"SM_CHANNEL_TRAIN\"))\n",
    "    parser.add_argument(\"--validation\", type=str, default=os.environ.get(\"SM_CHANNEL_VALIDATION\"))\n",
    "    parser.add_argument(\"--sm_hosts\", type=str, default=os.environ.get(\"SM_HOSTS\"))\n",
    "    parser.add_argument(\"--sm_current_host\", type=str, default=os.environ.get(\"SM_CURRENT_HOST\"))\n",
    "\n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    X_train, y_train, X_val, y_val = prepare_data(args.train, args.validation)\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    dtrain = xgb.DMatrix(data=X_train, label=y_train)\n",
    "    dval = xgb.DMatrix(data=X_val, label=y_val)\n",
    "    watchlist = [(dtrain, \"train\"), (dval, \"validation\")]\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        \"booster\": \"gbtree\",\n",
    "        \"objective\": args.objective,\n",
    "        \"learning_rate\": args.learning_rate,\n",
    "        \"gamma\": args.gamma,\n",
    "        \"min_child_weight\": args.min_child_weight,\n",
    "        \"max_depth\": args.max_depth,\n",
    "        \"subsample\": args.subsample,\n",
    "        \"colsample_bytree\": 1,\n",
    "        \"reg_lambda\": 1,\n",
    "        \"reg_alpha\": 0,\n",
    "        \"eval_metric\": \"rmse\",\n",
    "    }\n",
    "\n",
    "    bst = xgb.train(\n",
    "        params=params,\n",
    "        dtrain=dtrain,\n",
    "        num_boost_round=args.num_round,\n",
    "        evals=watchlist,\n",
    "        xgb_model=None,\n",
    "    )\n",
    "\n",
    "    model_location = args.model_dir + \"/xgboost-model\"\n",
    "    pkl.dump(bst, open(model_location, \"wb\"))\n",
    "    logging.info(\"Stored trained model at {}\".format(model_location))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.inputs import TrainingInput\n",
    "\n",
    "model_path = f\"s3://{default_bucket}/{s3_prefix}/model\"\n",
    "image_uri = sagemaker.image_uris.retrieve(\n",
    "    framework=\"xgboost\",\n",
    "    region=region,\n",
    "    version=\"1.5-1\",\n",
    "    instance_type=instance_type,\n",
    ")\n",
    "\n",
    "xgb_train = Estimator(\n",
    "    image_uri=image_uri,\n",
    "    entry_point=\"code/abalone.py\",\n",
    "    instance_type=instance_type,\n",
    "    instance_count=training_instance_count,\n",
    "    output_path=model_path,\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session\n",
    ")\n",
    "\n",
    "xgb_train.set_hyperparameters(\n",
    "    objective=\"reg:squarederror\",\n",
    "    learning_rate=0.01,\n",
    "    num_round=50,\n",
    "    max_depth=5,\n",
    "    eta=0.2,\n",
    "    gamma=4,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.7,\n",
    ")\n",
    "\n",
    "train_args = xgb_train.fit(\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"train\"].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "        \"validation\": TrainingInput(\n",
    "            s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\n",
    "                \"validation\"\n",
    "            ].S3Output.S3Uri,\n",
    "            content_type=\"text/csv\",\n",
    "        ),\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use the output of the estimator's `.fit()` method as arguments to the `TrainingStep`. By passing the `local_pipeline_session` to the `sagemaker_session`, calling `.fit()` does not launch the training job, it returns the arguments needed to run the job as a step in the pipeline.\n",
    "\n",
    "Pass in the `S3Uri` of the `\"train_data\"` output channel to the `.fit()` method. Also, use the other `\"test_data\"` output channel for model evaluation in the pipeline. The `properties` attribute of a Pipeline step matches the object model of the corresponding response of a describe call. These properties can be referenced as placeholder values and are resolved at runtime. For example, the `ProcessingStep` `properties` attribute matches the object model of the [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"AbaloneTrain\",\n",
    "    step_args=train_args,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Model Evaluation Step to Evaluate the Trained Model\n",
    "\n",
    "First, develop an evaluation script that is specified in a Processing step that performs the model evaluation.\n",
    "\n",
    "After pipeline execution, you can examine the resulting `evaluation.json` for analysis.\n",
    "\n",
    "The evaluation script uses `xgboost` to do the following:\n",
    "\n",
    "* Load the model.\n",
    "* Read the test data.\n",
    "* Issue predictions against the test data.\n",
    "* Build a classification report, including accuracy and ROC curve.\n",
    "* Save the evaluation report to the evaluation directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/evaluation.py\n",
    "import json\n",
    "import pathlib\n",
    "import pickle\n",
    "import tarfile\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "import math\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model_path = f\"/opt/ml/processing/model/model.tar.gz\"\n",
    "    with tarfile.open(model_path) as tar:\n",
    "        tar.extractall(path=\".\")\n",
    "\n",
    "    model = pickle.load(open(\"xgboost-model\", \"rb\"))\n",
    "\n",
    "    test_path = \"/opt/ml/processing/test/test.csv\"\n",
    "    df = pd.read_csv(test_path, header=None)\n",
    "    df.columns = [\"target\"] + [f\"feature_{x}\" for x in range(df.shape[1] - 1)]\n",
    "\n",
    "    y_test = df.iloc[:, 0].to_numpy()\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "\n",
    "    X_test = xgboost.DMatrix(df.values)\n",
    "\n",
    "    predictions = model.predict(X_test)\n",
    "\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    std = np.std(y_test - predictions)\n",
    "    report_dict = {\n",
    "        \"regression_metrics\": {\n",
    "            \"mse\": {\"value\": math.sqrt(mse), \"standard_deviation\": std},\n",
    "        },\n",
    "    }\n",
    "\n",
    "    output_dir = \"/opt/ml/processing/evaluation\"\n",
    "    pathlib.Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    evaluation_path = f\"{output_dir}/evaluation.json\"\n",
    "    with open(evaluation_path, \"w\") as f:\n",
    "        f.write(json.dumps(report_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create an instance of a `ScriptProcessor` processor and use it in the `ProcessingStep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_eval = ScriptProcessor(\n",
    "    image_uri=image_uri,\n",
    "    command=[\"python3\"],\n",
    "    instance_type=instance_type,\n",
    "    instance_count=processing_instance_count,\n",
    "    base_job_name=\"script-abalone-eval\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n",
    "\n",
    "eval_args = script_eval.run(\n",
    "    inputs=[\n",
    "        ProcessingInput(\n",
    "            source=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "            destination=\"/opt/ml/processing/model\",\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            source=step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "            destination=\"/opt/ml/processing/test\",\n",
    "        ),\n",
    "    ],\n",
    "    outputs=[\n",
    "        ProcessingOutput(output_name=\"evaluation\", source=\"/opt/ml/processing/evaluation\"),\n",
    "    ],\n",
    "    code=\"code/evaluation.py\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the processor's arguments returned by `.run()` to construct a `ProcessingStep`, along with the input and output channels and the code that will be executed when the pipeline invokes pipeline execution. \n",
    "\n",
    "Specifically, the `S3ModelArtifacts` from the `step_train` `properties` and the `S3Uri` of the `\"test_data\"` output channel of the `step_process` `properties` are passed as inputs. The `TrainingStep` and `ProcessingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) and [DescribeProcessingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeProcessingJob.html) response objects, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.properties import PropertyFile\n",
    "\n",
    "evaluation_report = PropertyFile(\n",
    "    name=\"EvaluationReport\", output_name=\"evaluation\", path=\"evaluation.json\"\n",
    ")\n",
    "step_eval = ProcessingStep(\n",
    "    name=\"AbaloneEval\",\n",
    "    step_args=eval_args,\n",
    "    property_files=[evaluation_report],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Create Model Step to Create a Model\n",
    "\n",
    "In order to perform batch transformation using the example model, create a SageMaker model. \n",
    "\n",
    "Specifically, pass in the `S3ModelArtifacts` from the `TrainingStep`, `step_train` properties. The `TrainingStep` `properties` attribute matches the object model of the [DescribeTrainingJob](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeTrainingJob.html) response object.\n",
    "\n",
    "We provide a custom inference script that defines the logic for the batch transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile code/inference.py\n",
    "\n",
    "import json\n",
    "import os\n",
    "import pickle as pkl\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sagemaker_xgboost_container.encoder as xgb_encoders\n",
    "import xgboost as xgb\n",
    "import io\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    \"\"\"\n",
    "    Deserialize and return fitted model.\n",
    "    \"\"\"\n",
    "    model_file = \"xgboost-model\"\n",
    "    booster = pkl.load(open(os.path.join(model_dir, model_file), \"rb\"))\n",
    "    return booster\n",
    "\n",
    "def transform_fn(model, request_body, request_content_type, accept):\n",
    "    \"\"\" \"\"\"\n",
    "    if request_content_type == \"text/libsvm\":\n",
    "        input_data = xgb_encoders.libsvm_to_dmatrix(request_body)\n",
    "    if request_content_type == \"text/csv\":\n",
    "        df = pd.read_csv(io.StringIO(request_body.strip(\"\\n\")), header=None)\n",
    "        df.drop(0, axis=1, inplace=True)\n",
    "        input_data = xgb.DMatrix(data=df)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Content type {} is not supported.\".format(request_content_type))\n",
    "\n",
    "    prediction = model.predict(input_data)\n",
    "    feature_contribs = model.predict(input_data, pred_contribs=True, validate_features=False)\n",
    "    output = np.hstack((prediction[:, np.newaxis], feature_contribs))\n",
    "\n",
    "    logging.info(\"Successfully completed transform job!\")\n",
    "\n",
    "    return \",\".join(str(x) for x in output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.model import Model\n",
    "\n",
    "model = Model(\n",
    "    image_uri=image_uri,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    source_dir=\"code\",\n",
    "    entry_point=\"inference.py\",\n",
    "    role=role,\n",
    "    sagemaker_session=pipeline_session,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the `ModelStep` by providing the return values from `model.create()` as the step arguments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.model_step import ModelStep\n",
    "\n",
    "step_create_model = ModelStep(\n",
    "    name=\"AbaloneCreateModel\", step_args=model.create(instance_type=instance_type)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Transform Step to Perform Batch Transformation\n",
    "\n",
    "Now that a model instance is defined, create a `Transformer` instance with the appropriate model type, compute instance type, and desired output S3 URI.\n",
    "\n",
    "Specifically, pass in the `ModelName` from the `CreateModelStep`, `step_create_model` properties. The `CreateModelStep` `properties` attribute matches the object model of the [DescribeModel](https://docs.aws.amazon.com/sagemaker/latest/APIReference/API_DescribeModel.html) response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.transformer import Transformer\n",
    "\n",
    "\n",
    "transformer = Transformer(\n",
    "    model_name=step_create_model.properties.ModelName,\n",
    "    instance_type=instance_type,\n",
    "    instance_count=transform_instance_count,\n",
    "    output_path=f\"s3://{default_bucket}/{s3_prefix}/transform\",\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass in the transformer instance and the `TransformInput` with the `batch_data` pipeline parameter defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TransformInput\n",
    "from sagemaker.workflow.steps import TransformStep\n",
    "from sagemaker.workflow.functions import Join\n",
    "\n",
    "transform_data = Join(\n",
    "    on=\"/\",\n",
    "    values=[\n",
    "        step_process.properties.ProcessingOutputConfig.Outputs[\"test\"].S3Output.S3Uri,\n",
    "        \"test.csv\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "transform_args = transformer.transform(transform_data, content_type=\"text/csv\")\n",
    "\n",
    "step_transform = TransformStep(name=\"AbaloneTransform\", step_args=transform_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.fail_step import FailStep\n",
    "\n",
    "step_fail = FailStep(\n",
    "    name=\"AbaloneMSEFail\",\n",
    "    error_message=Join(on=\" \", values=[\"Execution failed due to MSE >\", mse_threshold]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Condition Step to Check Accuracy and Conditionally Create a Model and Run a Batch Transformation Or Terminate the Execution in Failed State\n",
    "\n",
    "In this step, the model is registered only if the accuracy of the model, as determined by the evaluation step `step_eval`, exceeded a specified value. Otherwise, the pipeline execution fails and terminates. A `ConditionStep` enables pipelines to support conditional execution in the pipeline DAG based on the conditions of the step properties.\n",
    "\n",
    "In the following section, you:\n",
    "\n",
    "* Define a `ConditionLessThanOrEqualTo` on the accuracy value found in the output of the evaluation step, `step_eval`.\n",
    "* Use the condition in the list of conditions in a `ConditionStep`.\n",
    "* Pass the `CreateModelStep` and `TransformStep` steps into the `if_steps` of the `ConditionStep`, which are only executed if the condition evaluates to `True`.\n",
    "* Pass the `FailStep` step into the `else_steps`of the `ConditionStep`, which is only executed if the condition evaluates to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.conditions import ConditionLessThanOrEqualTo\n",
    "from sagemaker.workflow.condition_step import ConditionStep\n",
    "from sagemaker.workflow.functions import JsonGet\n",
    "\n",
    "cond_lte = ConditionLessThanOrEqualTo(\n",
    "    left=JsonGet(\n",
    "        step_name=step_eval.name,\n",
    "        property_file=evaluation_report,\n",
    "        json_path=\"regression_metrics.mse.value\",\n",
    "    ),\n",
    "    right=mse_threshold,\n",
    ")\n",
    "\n",
    "step_cond = ConditionStep(\n",
    "    name=\"AbaloneMSECond\",\n",
    "    conditions=[cond_lte],\n",
    "    if_steps=[step_create_model, step_transform],\n",
    "    else_steps=[step_fail],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a Pipeline\n",
    "\n",
    "In this section, combine the steps into a Pipeline so it can be executed. Depending on the `pipeline_session` variable the steps in the pipeline will run either locally on your machine or in the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        input_data,\n",
    "        mse_threshold,\n",
    "    ],\n",
    "    steps=[step_process, step_train, step_eval, step_cond],\n",
    "    sagemaker_session=pipeline_session,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Examining the pipeline definition\n",
    "\n",
    "The JSON of the pipeline definition can be examined to confirm the pipeline is well-defined and the parameters and step properties resolve correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "definition = json.loads(pipeline.definition())\n",
    "definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit the pipeline to SageMaker and start execution\n",
    "\n",
    "Submit the pipeline definition to the Pipeline service. The Pipeline service uses the role that is passed in to create all the jobs defined in the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.upsert(role_arn=role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start the pipeline and accept all the default parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fawwqfmz6x-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "fawwqfmz6x-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10 09:02:24.317 default:1 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10 09:02:24.335 default:1 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Imported framework sagemaker_xgboost_container.training\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\n",
      "fawwqfmz6x-sagemaker-local  | Returning the value itself\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] No GPUs detected (normal if no gpus installed)\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Invoking user training script.\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Module abalone does not provide a setup.py. \n",
      "fawwqfmz6x-sagemaker-local  | Generating setup.py\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Generating setup.cfg\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Generating MANIFEST.in\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:24:INFO] Installing module with the following command:\n",
      "fawwqfmz6x-sagemaker-local  | /miniconda3/bin/python3 -m pip install . \n",
      "fawwqfmz6x-sagemaker-local  | Processing /opt/ml/code\n",
      "fawwqfmz6x-sagemaker-local  |   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "fawwqfmz6x-sagemaker-local  | \u001b[?25hBuilding wheels for collected packages: abalone\n",
      "fawwqfmz6x-sagemaker-local  |   Building wheel for abalone (setup.py) ... \u001b[?25ldone\n",
      "fawwqfmz6x-sagemaker-local  | \u001b[?25h  Created wheel for abalone: filename=abalone-1.0.0-py2.py3-none-any.whl size=5603 sha256=cfff5f71936ac2fdc2f160bbd7f324a89832f3cd97f28294bc8cdc77b579d3cf\n",
      "fawwqfmz6x-sagemaker-local  |   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-mhr2ji_s/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "fawwqfmz6x-sagemaker-local  | Successfully built abalone\n",
      "fawwqfmz6x-sagemaker-local  | Installing collected packages: abalone\n",
      "fawwqfmz6x-sagemaker-local  | Successfully installed abalone-1.0.0\n",
      "fawwqfmz6x-sagemaker-local  | \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "fawwqfmz6x-sagemaker-local  | \u001b[0m[2024-01-10:09:02:26:INFO] Failed to parse hyperparameter objective value reg:squarederror to Json.\n",
      "fawwqfmz6x-sagemaker-local  | Returning the value itself\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:26:INFO] No GPUs detected (normal if no gpus installed)\n",
      "fawwqfmz6x-sagemaker-local  | [2024-01-10:09:02:26:INFO] Invoking user script\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | Training Env:\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | {\n",
      "fawwqfmz6x-sagemaker-local  |     \"additional_framework_parameters\": {},\n",
      "fawwqfmz6x-sagemaker-local  |     \"channel_input_dirs\": {\n",
      "fawwqfmz6x-sagemaker-local  |         \"train\": \"/opt/ml/input/data/train\",\n",
      "fawwqfmz6x-sagemaker-local  |         \"validation\": \"/opt/ml/input/data/validation\"\n",
      "fawwqfmz6x-sagemaker-local  |     },\n",
      "fawwqfmz6x-sagemaker-local  |     \"current_host\": \"sagemaker-local\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"framework_module\": \"sagemaker_xgboost_container.training:main\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"hosts\": [\n",
      "fawwqfmz6x-sagemaker-local  |         \"sagemaker-local\"\n",
      "fawwqfmz6x-sagemaker-local  |     ],\n",
      "fawwqfmz6x-sagemaker-local  |     \"hyperparameters\": {\n",
      "fawwqfmz6x-sagemaker-local  |         \"objective\": \"reg:squarederror\",\n",
      "fawwqfmz6x-sagemaker-local  |         \"learning_rate\": 0.01,\n",
      "fawwqfmz6x-sagemaker-local  |         \"num_round\": 50,\n",
      "fawwqfmz6x-sagemaker-local  |         \"max_depth\": 5,\n",
      "fawwqfmz6x-sagemaker-local  |         \"eta\": 0.2,\n",
      "fawwqfmz6x-sagemaker-local  |         \"gamma\": 4,\n",
      "fawwqfmz6x-sagemaker-local  |         \"min_child_weight\": 6,\n",
      "fawwqfmz6x-sagemaker-local  |         \"subsample\": 0.7\n",
      "fawwqfmz6x-sagemaker-local  |     },\n",
      "fawwqfmz6x-sagemaker-local  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"input_data_config\": {\n",
      "fawwqfmz6x-sagemaker-local  |         \"train\": {\n",
      "fawwqfmz6x-sagemaker-local  |             \"TrainingInputMode\": \"File\",\n",
      "fawwqfmz6x-sagemaker-local  |             \"ContentType\": \"text/csv\"\n",
      "fawwqfmz6x-sagemaker-local  |         },\n",
      "fawwqfmz6x-sagemaker-local  |         \"validation\": {\n",
      "fawwqfmz6x-sagemaker-local  |             \"TrainingInputMode\": \"File\",\n",
      "fawwqfmz6x-sagemaker-local  |             \"ContentType\": \"text/csv\"\n",
      "fawwqfmz6x-sagemaker-local  |         }\n",
      "fawwqfmz6x-sagemaker-local  |     },\n",
      "fawwqfmz6x-sagemaker-local  |     \"input_dir\": \"/opt/ml/input\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"is_master\": true,\n",
      "fawwqfmz6x-sagemaker-local  |     \"job_name\": \"AbaloneTrain-1704877342-477e\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"log_level\": 20,\n",
      "fawwqfmz6x-sagemaker-local  |     \"master_hostname\": \"sagemaker-local\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"model_dir\": \"/opt/ml/model\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"module_dir\": \"s3://sagemaker-us-east-1-626723862963/LocalModePipeline/code/eb67df0d53fdce5b483bbde46a017e78/sourcedir.tar.gz\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"module_name\": \"abalone\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"network_interface_name\": \"eth0\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"num_cpus\": 8,\n",
      "fawwqfmz6x-sagemaker-local  |     \"num_gpus\": 0,\n",
      "fawwqfmz6x-sagemaker-local  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"output_dir\": \"/opt/ml/output\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "fawwqfmz6x-sagemaker-local  |     \"resource_config\": {\n",
      "fawwqfmz6x-sagemaker-local  |         \"current_host\": \"sagemaker-local\",\n",
      "fawwqfmz6x-sagemaker-local  |         \"hosts\": [\n",
      "fawwqfmz6x-sagemaker-local  |             \"sagemaker-local\"\n",
      "fawwqfmz6x-sagemaker-local  |         ]\n",
      "fawwqfmz6x-sagemaker-local  |     },\n",
      "fawwqfmz6x-sagemaker-local  |     \"user_entry_point\": \"abalone.py\"\n",
      "fawwqfmz6x-sagemaker-local  | }\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | Environment variables:\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | SM_HOSTS=[\"sagemaker-local\"]\n",
      "fawwqfmz6x-sagemaker-local  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "fawwqfmz6x-sagemaker-local  | SM_HPS={\"eta\":0.2,\"gamma\":4,\"learning_rate\":0.01,\"max_depth\":5,\"min_child_weight\":6,\"num_round\":50,\"objective\":\"reg:squarederror\",\"subsample\":0.7}\n",
      "fawwqfmz6x-sagemaker-local  | SM_USER_ENTRY_POINT=abalone.py\n",
      "fawwqfmz6x-sagemaker-local  | SM_FRAMEWORK_PARAMS={}\n",
      "fawwqfmz6x-sagemaker-local  | SM_RESOURCE_CONFIG={\"current_host\":\"sagemaker-local\",\"hosts\":[\"sagemaker-local\"]}\n",
      "fawwqfmz6x-sagemaker-local  | SM_INPUT_DATA_CONFIG={\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}}\n",
      "fawwqfmz6x-sagemaker-local  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "fawwqfmz6x-sagemaker-local  | SM_CHANNELS=[\"train\",\"validation\"]\n",
      "fawwqfmz6x-sagemaker-local  | SM_CURRENT_HOST=sagemaker-local\n",
      "fawwqfmz6x-sagemaker-local  | SM_MODULE_NAME=abalone\n",
      "fawwqfmz6x-sagemaker-local  | SM_LOG_LEVEL=20\n",
      "fawwqfmz6x-sagemaker-local  | SM_FRAMEWORK_MODULE=sagemaker_xgboost_container.training:main\n",
      "fawwqfmz6x-sagemaker-local  | SM_INPUT_DIR=/opt/ml/input\n",
      "fawwqfmz6x-sagemaker-local  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "fawwqfmz6x-sagemaker-local  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "fawwqfmz6x-sagemaker-local  | SM_NUM_CPUS=8\n",
      "fawwqfmz6x-sagemaker-local  | SM_NUM_GPUS=0\n",
      "fawwqfmz6x-sagemaker-local  | SM_MODEL_DIR=/opt/ml/model\n",
      "fawwqfmz6x-sagemaker-local  | SM_MODULE_DIR=s3://sagemaker-us-east-1-626723862963/LocalModePipeline/code/eb67df0d53fdce5b483bbde46a017e78/sourcedir.tar.gz\n",
      "fawwqfmz6x-sagemaker-local  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"train\":\"/opt/ml/input/data/train\",\"validation\":\"/opt/ml/input/data/validation\"},\"current_host\":\"sagemaker-local\",\"framework_module\":\"sagemaker_xgboost_container.training:main\",\"hosts\":[\"sagemaker-local\"],\"hyperparameters\":{\"eta\":0.2,\"gamma\":4,\"learning_rate\":0.01,\"max_depth\":5,\"min_child_weight\":6,\"num_round\":50,\"objective\":\"reg:squarederror\",\"subsample\":0.7},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"train\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"},\"validation\":{\"ContentType\":\"text/csv\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"AbaloneTrain-1704877342-477e\",\"log_level\":20,\"master_hostname\":\"sagemaker-local\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-626723862963/LocalModePipeline/code/eb67df0d53fdce5b483bbde46a017e78/sourcedir.tar.gz\",\"module_name\":\"abalone\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"sagemaker-local\",\"hosts\":[\"sagemaker-local\"]},\"user_entry_point\":\"abalone.py\"}\n",
      "fawwqfmz6x-sagemaker-local  | SM_USER_ARGS=[\"--eta\",\"0.2\",\"--gamma\",\"4\",\"--learning_rate\",\"0.01\",\"--max_depth\",\"5\",\"--min_child_weight\",\"6\",\"--num_round\",\"50\",\"--objective\",\"reg:squarederror\",\"--subsample\",\"0.7\"]\n",
      "fawwqfmz6x-sagemaker-local  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "fawwqfmz6x-sagemaker-local  | SM_CHANNEL_TRAIN=/opt/ml/input/data/train\n",
      "fawwqfmz6x-sagemaker-local  | SM_CHANNEL_VALIDATION=/opt/ml/input/data/validation\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_OBJECTIVE=reg:squarederror\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_LEARNING_RATE=0.01\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_NUM_ROUND=50\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_MAX_DEPTH=5\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_ETA=0.2\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_GAMMA=4\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_MIN_CHILD_WEIGHT=6\n",
      "fawwqfmz6x-sagemaker-local  | SM_HP_SUBSAMPLE=0.7\n",
      "fawwqfmz6x-sagemaker-local  | PYTHONPATH=/miniconda3/bin:/:/miniconda3/lib/python/site-packages/xgboost/dmlc-core/tracker:/miniconda3/lib/python38.zip:/miniconda3/lib/python3.8:/miniconda3/lib/python3.8/lib-dynload:/miniconda3/lib/python3.8/site-packages\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | Invoking script with the following command:\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | /miniconda3/bin/python3 -m abalone --eta 0.2 --gamma 4 --learning_rate 0.01 --max_depth 5 --min_child_weight 6 --num_round 50 --objective reg:squarederror --subsample 0.7\n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | \n",
      "fawwqfmz6x-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "fawwqfmz6x-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "fawwqfmz6x-sagemaker-local  | [0]\ttrain-rmse:9.92045\tvalidation-rmse:9.77319\n",
      "fawwqfmz6x-sagemaker-local  | [1]\ttrain-rmse:9.82700\tvalidation-rmse:9.68162\n",
      "fawwqfmz6x-sagemaker-local  | [2]\ttrain-rmse:9.73507\tvalidation-rmse:9.59128\n",
      "fawwqfmz6x-sagemaker-local  | [3]\ttrain-rmse:9.64414\tvalidation-rmse:9.50194\n",
      "fawwqfmz6x-sagemaker-local  | [4]\ttrain-rmse:9.55391\tvalidation-rmse:9.41366\n",
      "fawwqfmz6x-sagemaker-local  | [5]\ttrain-rmse:9.46489\tvalidation-rmse:9.32582\n",
      "fawwqfmz6x-sagemaker-local  | [6]\ttrain-rmse:9.37725\tvalidation-rmse:9.24037\n",
      "fawwqfmz6x-sagemaker-local  | [7]\ttrain-rmse:9.28951\tvalidation-rmse:9.15443\n",
      "fawwqfmz6x-sagemaker-local  | [8]\ttrain-rmse:9.20246\tvalidation-rmse:9.06903\n",
      "fawwqfmz6x-sagemaker-local  | [9]\ttrain-rmse:9.11674\tvalidation-rmse:8.98505\n",
      "fawwqfmz6x-sagemaker-local  | [10]\ttrain-rmse:9.03256\tvalidation-rmse:8.90200\n",
      "fawwqfmz6x-sagemaker-local  | [11]\ttrain-rmse:8.94883\tvalidation-rmse:8.82043\n",
      "fawwqfmz6x-sagemaker-local  | [12]\ttrain-rmse:8.86605\tvalidation-rmse:8.73970\n",
      "fawwqfmz6x-sagemaker-local  | [13]\ttrain-rmse:8.78380\tvalidation-rmse:8.65949\n",
      "fawwqfmz6x-sagemaker-local  | [14]\ttrain-rmse:8.70285\tvalidation-rmse:8.58010\n",
      "fawwqfmz6x-sagemaker-local  | [15]\ttrain-rmse:8.62208\tvalidation-rmse:8.50064\n",
      "fawwqfmz6x-sagemaker-local  | [16]\ttrain-rmse:8.54204\tvalidation-rmse:8.42221\n",
      "fawwqfmz6x-sagemaker-local  | [17]\ttrain-rmse:8.46317\tvalidation-rmse:8.34479\n",
      "fawwqfmz6x-sagemaker-local  | [18]\ttrain-rmse:8.38548\tvalidation-rmse:8.26836\n",
      "fawwqfmz6x-sagemaker-local  | [19]\ttrain-rmse:8.30852\tvalidation-rmse:8.19327\n",
      "fawwqfmz6x-sagemaker-local  | [20]\ttrain-rmse:8.23165\tvalidation-rmse:8.11790\n",
      "fawwqfmz6x-sagemaker-local  | [21]\ttrain-rmse:8.15597\tvalidation-rmse:8.04321\n",
      "fawwqfmz6x-sagemaker-local  | [22]\ttrain-rmse:8.08088\tvalidation-rmse:7.96984\n",
      "fawwqfmz6x-sagemaker-local  | [23]\ttrain-rmse:8.00731\tvalidation-rmse:7.89733\n",
      "fawwqfmz6x-sagemaker-local  | [24]\ttrain-rmse:7.93390\tvalidation-rmse:7.82505\n",
      "fawwqfmz6x-sagemaker-local  | [25]\ttrain-rmse:7.86137\tvalidation-rmse:7.75385\n",
      "fawwqfmz6x-sagemaker-local  | [26]\ttrain-rmse:7.78895\tvalidation-rmse:7.68229\n",
      "fawwqfmz6x-sagemaker-local  | [27]\ttrain-rmse:7.71820\tvalidation-rmse:7.61331\n",
      "fawwqfmz6x-sagemaker-local  | [28]\ttrain-rmse:7.64815\tvalidation-rmse:7.54368\n",
      "fawwqfmz6x-sagemaker-local  | [29]\ttrain-rmse:7.57860\tvalidation-rmse:7.47540\n",
      "fawwqfmz6x-sagemaker-local  | [30]\ttrain-rmse:7.51019\tvalidation-rmse:7.40842\n",
      "fawwqfmz6x-sagemaker-local  | [31]\ttrain-rmse:7.44246\tvalidation-rmse:7.34212\n",
      "fawwqfmz6x-sagemaker-local  | [32]\ttrain-rmse:7.37558\tvalidation-rmse:7.27652\n",
      "fawwqfmz6x-sagemaker-local  | [33]\ttrain-rmse:7.30860\tvalidation-rmse:7.21020\n",
      "fawwqfmz6x-sagemaker-local  | [34]\ttrain-rmse:7.24302\tvalidation-rmse:7.14593\n",
      "fawwqfmz6x-sagemaker-local  | [35]\ttrain-rmse:7.17723\tvalidation-rmse:7.08150\n",
      "fawwqfmz6x-sagemaker-local  | [36]\ttrain-rmse:7.11266\tvalidation-rmse:7.01789\n",
      "fawwqfmz6x-sagemaker-local  | [37]\ttrain-rmse:7.04939\tvalidation-rmse:6.95498\n",
      "fawwqfmz6x-sagemaker-local  | [38]\ttrain-rmse:6.98610\tvalidation-rmse:6.89233\n",
      "fawwqfmz6x-sagemaker-local  | [39]\ttrain-rmse:6.92339\tvalidation-rmse:6.83025\n",
      "fawwqfmz6x-sagemaker-local  | [40]\ttrain-rmse:6.86200\tvalidation-rmse:6.77045\n",
      "fawwqfmz6x-sagemaker-local  | [41]\ttrain-rmse:6.80086\tvalidation-rmse:6.71065\n",
      "fawwqfmz6x-sagemaker-local  | [42]\ttrain-rmse:6.74020\tvalidation-rmse:6.65149\n",
      "fawwqfmz6x-sagemaker-local  | [43]\ttrain-rmse:6.68009\tvalidation-rmse:6.59252\n",
      "fawwqfmz6x-sagemaker-local  | [44]\ttrain-rmse:6.62082\tvalidation-rmse:6.53451\n",
      "fawwqfmz6x-sagemaker-local  | [45]\ttrain-rmse:6.56272\tvalidation-rmse:6.47792\n",
      "fawwqfmz6x-sagemaker-local  | [46]\ttrain-rmse:6.50482\tvalidation-rmse:6.42115\n",
      "fawwqfmz6x-sagemaker-local  | [47]\ttrain-rmse:6.44817\tvalidation-rmse:6.36552\n",
      "fawwqfmz6x-sagemaker-local  | [48]\ttrain-rmse:6.39125\tvalidation-rmse:6.30925\n",
      "fawwqfmz6x-sagemaker-local  | [49]\ttrain-rmse:6.33518\tvalidation-rmse:6.25390\n",
      "fawwqfmz6x-sagemaker-local  | INFO:root:Stored trained model at /opt/ml/model/xgboost-model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /home/sagemaker-user/tmp/tmp8nsye40m/artifacts/output/data\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmp8nsye40m/model/xgboost-model -> /home/sagemaker-user/tmp/tmp8nsye40m/artifacts/model\n",
      "INFO:sagemaker.local.image:===== Job Complete =====\n",
      "INFO:sagemaker.local.entities:Pipeline step 'AbaloneTrain' SUCCEEDED.\n",
      "INFO:sagemaker.local.entities:Starting pipeline step: 'AbaloneEval'\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.local_session:Starting processing job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fawwqfmz6x-sagemaker-local exited with code 0\n",
      "Aborting on container exit...\n",
      " Container fawwqfmz6x-sagemaker-local  Stopping\n",
      " Container fawwqfmz6x-sagemaker-local  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Using the short-lived AWS credentials found in session. They might expire while running.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "services:\n",
      "  sagemaker-local:\n",
      "    container_name: zury29wzzl-sagemaker-local\n",
      "    entrypoint:\n",
      "    - python3\n",
      "    - /opt/ml/processing/input/code/evaluation.py\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1\n",
      "    network_mode: sagemaker\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /home/sagemaker-user/tmp/tmphb1pume3/sagemaker-local/output:/opt/ml/output\n",
      "    - /home/sagemaker-user/tmp/tmphb1pume3/sagemaker-local/config:/opt/ml/config\n",
      "    - /home/sagemaker-user/tmp/tmpby7s5dl3:/opt/ml/processing/model\n",
      "    - /home/sagemaker-user/tmp/tmptjm2c1qn:/opt/ml/processing/test\n",
      "    - /home/sagemaker-user/tmp/tmpzpzefpq1:/opt/ml/processing/input/code\n",
      "    - /home/sagemaker-user/tmp/tmp60cysnbc/output/evaluation:/opt/ml/processing/evaluation\n",
      "    - /home/sagemaker-user/tmp/tmphb1pume3/shared:/opt/ml/shared\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f /home/sagemaker-user/tmp/tmphb1pume3/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container zury29wzzl-sagemaker-local  Creating\n",
      " Container zury29wzzl-sagemaker-local  Created\n",
      "Attaching to zury29wzzl-sagemaker-local\n",
      "zury29wzzl-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "zury29wzzl-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.image:===== Job Complete =====\n",
      "INFO:sagemaker.local.entities:Pipeline step 'AbaloneEval' SUCCEEDED.\n",
      "INFO:sagemaker.local.entities:Starting pipeline step: 'AbaloneMSECond'\n",
      "INFO:sagemaker.local.entities:Pipeline step 'AbaloneMSECond' SUCCEEDED.\n",
      "INFO:sagemaker.local.entities:Starting pipeline step: 'AbaloneCreateModel-RepackModel-0'\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.local_session:Starting training job\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zury29wzzl-sagemaker-local exited with code 0\n",
      "Aborting on container exit...\n",
      " Container zury29wzzl-sagemaker-local  Stopping\n",
      " Container zury29wzzl-sagemaker-local  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker.local.image:Using the short-lived AWS credentials found in session. They might expire while running.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "services:\n",
      "  sagemaker-local:\n",
      "    command: train\n",
      "    container_name: vgnydp4ndx-sagemaker-local\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\n",
      "    network_mode: sagemaker\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /home/sagemaker-user/tmp/tmpcph4shj4/sagemaker-local/output/data:/opt/ml/output/data\n",
      "    - /home/sagemaker-user/tmp/tmpcph4shj4/sagemaker-local/output:/opt/ml/output\n",
      "    - /home/sagemaker-user/tmp/tmpcph4shj4/sagemaker-local/input:/opt/ml/input\n",
      "    - /home/sagemaker-user/tmp/tmpcph4shj4/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "    - /home/sagemaker-user/tmp/tmp2mfip4cx:/opt/ml/input/data/training\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f /home/sagemaker-user/tmp/tmpcph4shj4/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Container vgnydp4ndx-sagemaker-local  Creating\n",
      " Container vgnydp4ndx-sagemaker-local  Created\n",
      "Attaching to vgnydp4ndx-sagemaker-local\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:30,929 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:30,931 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:30,932 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz to Json.\n",
      "vgnydp4ndx-sagemaker-local  | Returning the value itself\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:30,965 sagemaker_sklearn_container.training INFO     Invoking user training script.\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,142 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,143 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz to Json.\n",
      "vgnydp4ndx-sagemaker-local  | Returning the value itself\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,152 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,152 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz to Json.\n",
      "vgnydp4ndx-sagemaker-local  | Returning the value itself\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,162 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,162 sagemaker-training-toolkit INFO     Failed to parse hyperparameter model_archive value s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz to Json.\n",
      "vgnydp4ndx-sagemaker-local  | Returning the value itself\n",
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,170 sagemaker-training-toolkit INFO     Invoking user script\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | Training Env:\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | {\n",
      "vgnydp4ndx-sagemaker-local  |     \"additional_framework_parameters\": {},\n",
      "vgnydp4ndx-sagemaker-local  |     \"channel_input_dirs\": {\n",
      "vgnydp4ndx-sagemaker-local  |         \"training\": \"/opt/ml/input/data/training\"\n",
      "vgnydp4ndx-sagemaker-local  |     },\n",
      "vgnydp4ndx-sagemaker-local  |     \"current_host\": \"sagemaker-local\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"hosts\": [\n",
      "vgnydp4ndx-sagemaker-local  |         \"sagemaker-local\"\n",
      "vgnydp4ndx-sagemaker-local  |     ],\n",
      "vgnydp4ndx-sagemaker-local  |     \"hyperparameters\": {\n",
      "vgnydp4ndx-sagemaker-local  |         \"inference_script\": \"inference.py\",\n",
      "vgnydp4ndx-sagemaker-local  |         \"model_archive\": \"s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz\",\n",
      "vgnydp4ndx-sagemaker-local  |         \"dependencies\": null,\n",
      "vgnydp4ndx-sagemaker-local  |         \"source_dir\": \"code\"\n",
      "vgnydp4ndx-sagemaker-local  |     },\n",
      "vgnydp4ndx-sagemaker-local  |     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"input_data_config\": {\n",
      "vgnydp4ndx-sagemaker-local  |         \"training\": {\n",
      "vgnydp4ndx-sagemaker-local  |             \"TrainingInputMode\": \"File\"\n",
      "vgnydp4ndx-sagemaker-local  |         }\n",
      "vgnydp4ndx-sagemaker-local  |     },\n",
      "vgnydp4ndx-sagemaker-local  |     \"input_dir\": \"/opt/ml/input\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"is_master\": true,\n",
      "vgnydp4ndx-sagemaker-local  |     \"job_name\": \"AbaloneCreateModel-RepackModel-0-1704877349-6fd9\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"log_level\": 20,\n",
      "vgnydp4ndx-sagemaker-local  |     \"master_hostname\": \"sagemaker-local\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"model_dir\": \"/opt/ml/model\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"module_dir\": \"s3://sagemaker-us-east-1-626723862963/AbaloneCreateModel-RepackModel-0-0499cb8d05df34d458cbff5c10071d9a/source/sourcedir.tar.gz\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"module_name\": \"_repack_script_launcher.sh\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"network_interface_name\": \"eth0\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"num_cpus\": 8,\n",
      "vgnydp4ndx-sagemaker-local  |     \"num_gpus\": 0,\n",
      "vgnydp4ndx-sagemaker-local  |     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"output_dir\": \"/opt/ml/output\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "vgnydp4ndx-sagemaker-local  |     \"resource_config\": {\n",
      "vgnydp4ndx-sagemaker-local  |         \"current_host\": \"sagemaker-local\",\n",
      "vgnydp4ndx-sagemaker-local  |         \"hosts\": [\n",
      "vgnydp4ndx-sagemaker-local  |             \"sagemaker-local\"\n",
      "vgnydp4ndx-sagemaker-local  |         ]\n",
      "vgnydp4ndx-sagemaker-local  |     },\n",
      "vgnydp4ndx-sagemaker-local  |     \"user_entry_point\": \"_repack_script_launcher.sh\"\n",
      "vgnydp4ndx-sagemaker-local  | }\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | Environment variables:\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | SM_HOSTS=[\"sagemaker-local\"]\n",
      "vgnydp4ndx-sagemaker-local  | SM_NETWORK_INTERFACE_NAME=eth0\n",
      "vgnydp4ndx-sagemaker-local  | SM_HPS={\"dependencies\":null,\"inference_script\":\"inference.py\",\"model_archive\":\"s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz\",\"source_dir\":\"code\"}\n",
      "vgnydp4ndx-sagemaker-local  | SM_USER_ENTRY_POINT=_repack_script_launcher.sh\n",
      "vgnydp4ndx-sagemaker-local  | SM_FRAMEWORK_PARAMS={}\n",
      "vgnydp4ndx-sagemaker-local  | SM_RESOURCE_CONFIG={\"current_host\":\"sagemaker-local\",\"hosts\":[\"sagemaker-local\"]}\n",
      "vgnydp4ndx-sagemaker-local  | SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "vgnydp4ndx-sagemaker-local  | SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "vgnydp4ndx-sagemaker-local  | SM_CHANNELS=[\"training\"]\n",
      "vgnydp4ndx-sagemaker-local  | SM_CURRENT_HOST=sagemaker-local\n",
      "vgnydp4ndx-sagemaker-local  | SM_MODULE_NAME=_repack_script_launcher.sh\n",
      "vgnydp4ndx-sagemaker-local  | SM_LOG_LEVEL=20\n",
      "vgnydp4ndx-sagemaker-local  | SM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\n",
      "vgnydp4ndx-sagemaker-local  | SM_INPUT_DIR=/opt/ml/input\n",
      "vgnydp4ndx-sagemaker-local  | SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "vgnydp4ndx-sagemaker-local  | SM_OUTPUT_DIR=/opt/ml/output\n",
      "vgnydp4ndx-sagemaker-local  | SM_NUM_CPUS=8\n",
      "vgnydp4ndx-sagemaker-local  | SM_NUM_GPUS=0\n",
      "vgnydp4ndx-sagemaker-local  | SM_MODEL_DIR=/opt/ml/model\n",
      "vgnydp4ndx-sagemaker-local  | SM_MODULE_DIR=s3://sagemaker-us-east-1-626723862963/AbaloneCreateModel-RepackModel-0-0499cb8d05df34d458cbff5c10071d9a/source/sourcedir.tar.gz\n",
      "vgnydp4ndx-sagemaker-local  | SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"sagemaker-local\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"sagemaker-local\"],\"hyperparameters\":{\"dependencies\":null,\"inference_script\":\"inference.py\",\"model_archive\":\"s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz\",\"source_dir\":\"code\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"AbaloneCreateModel-RepackModel-0-1704877349-6fd9\",\"log_level\":20,\"master_hostname\":\"sagemaker-local\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-626723862963/AbaloneCreateModel-RepackModel-0-0499cb8d05df34d458cbff5c10071d9a/source/sourcedir.tar.gz\",\"module_name\":\"_repack_script_launcher.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":8,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"sagemaker-local\",\"hosts\":[\"sagemaker-local\"]},\"user_entry_point\":\"_repack_script_launcher.sh\"}\n",
      "vgnydp4ndx-sagemaker-local  | SM_USER_ARGS=[\"--dependencies\",\"\",\"--inference_script\",\"inference.py\",\"--model_archive\",\"s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz\",\"--source_dir\",\"code\"]\n",
      "vgnydp4ndx-sagemaker-local  | SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "vgnydp4ndx-sagemaker-local  | SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "vgnydp4ndx-sagemaker-local  | SM_HP_INFERENCE_SCRIPT=inference.py\n",
      "vgnydp4ndx-sagemaker-local  | SM_HP_MODEL_ARCHIVE=s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz\n",
      "vgnydp4ndx-sagemaker-local  | SM_HP_DEPENDENCIES=\n",
      "vgnydp4ndx-sagemaker-local  | SM_HP_SOURCE_DIR=code\n",
      "vgnydp4ndx-sagemaker-local  | PYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | Invoking script with the following command:\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | /bin/sh -c ./_repack_script_launcher.sh --dependencies '' --inference_script inference.py --model_archive s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz --source_dir code\n",
      "vgnydp4ndx-sagemaker-local  | \n",
      "vgnydp4ndx-sagemaker-local  | \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/output/data\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/sagemaker-local/output/success -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/output\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/xgboost-model -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model\n",
      "INFO:root:creating /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/code/preprocessing.py -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/code/abalone.py -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/code/evaluation.py -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/code/inference.py -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/code/_repack_model.py -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n",
      "INFO:root:copying /home/sagemaker-user/tmp/tmpcph4shj4/model/code/_repack_script_launcher.sh -> /home/sagemaker-user/tmp/tmpcph4shj4/artifacts/model/code\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgnydp4ndx-sagemaker-local  | 2024-01-10 09:02:31,374 sagemaker-containers INFO     Reporting training SUCCESS\n",
      "vgnydp4ndx-sagemaker-local exited with code 0\n",
      "Aborting on container exit...\n",
      " Container vgnydp4ndx-sagemaker-local  Stopping\n",
      " Container vgnydp4ndx-sagemaker-local  Stopped\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.image:===== Job Complete =====\n",
      "INFO:sagemaker.local.entities:Pipeline step 'AbaloneCreateModel-RepackModel-0' SUCCEEDED.\n",
      "INFO:sagemaker.local.entities:Starting pipeline step: 'AbaloneCreateModel-CreateModel'\n",
      "INFO:sagemaker.local.entities:Pipeline step 'AbaloneCreateModel-CreateModel' SUCCEEDED.\n",
      "INFO:sagemaker.local.entities:Starting pipeline step: 'AbaloneTransform'\n",
      "INFO:sagemaker.local.image:'Docker Compose' found using Docker CLI.\n",
      "INFO:sagemaker.local.image:serving\n",
      "INFO:sagemaker.local.image:creating hosting dir in /home/sagemaker-user/tmp/tmpsdra9xpv\n",
      "WARNING:sagemaker.local.image:Using the short-lived AWS credentials found in session. They might expire while running.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "services:\n",
      "  sagemaker-local:\n",
      "    command: serve\n",
      "    container_name: 83m8maybyg-sagemaker-local\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 683313688378.dkr.ecr.us-east-1.amazonaws.com/sagemaker-xgboost:1.5-1\n",
      "    network_mode: sagemaker\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /home/sagemaker-user/tmp/tmp4r1zrjsq:/opt/ml/model\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker compose -f /home/sagemaker-user/tmp/tmpsdra9xpv/docker-compose.yaml up --build --abort-on-container-exit\n",
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 5\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb079403c70>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb0794e1480>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "WARNING:urllib3.connectionpool:Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<urllib3.connection.HTTPConnection object at 0x7fb0794e0c40>: Failed to establish a new connection: [Errno 111] Connection refused')': /ping\n",
      "INFO:sagemaker.local.entities:Container still not up, got: -1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attaching to 83m8maybyg-sagemaker-local\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] nginx config: \n",
      "83m8maybyg-sagemaker-local  | worker_processes auto;\n",
      "83m8maybyg-sagemaker-local  | daemon off;\n",
      "83m8maybyg-sagemaker-local  | pid /tmp/nginx.pid;\n",
      "83m8maybyg-sagemaker-local  | error_log  /dev/stderr;\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  | worker_rlimit_nofile 4096;\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  | events {\n",
      "83m8maybyg-sagemaker-local  |   worker_connections 2048;\n",
      "83m8maybyg-sagemaker-local  | }\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  | http {\n",
      "83m8maybyg-sagemaker-local  |   include /etc/nginx/mime.types;\n",
      "83m8maybyg-sagemaker-local  |   default_type application/octet-stream;\n",
      "83m8maybyg-sagemaker-local  |   access_log /dev/stdout combined;\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  |   upstream gunicorn {\n",
      "83m8maybyg-sagemaker-local  |     server unix:/tmp/gunicorn.sock;\n",
      "83m8maybyg-sagemaker-local  |   }\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  |   server {\n",
      "83m8maybyg-sagemaker-local  |     listen 8080 deferred;\n",
      "83m8maybyg-sagemaker-local  |     client_max_body_size 0;\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  |     keepalive_timeout 3;\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  |     location ~ ^/(ping|invocations|execution-parameters) {\n",
      "83m8maybyg-sagemaker-local  |       proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
      "83m8maybyg-sagemaker-local  |       proxy_set_header Host $http_host;\n",
      "83m8maybyg-sagemaker-local  |       proxy_redirect off;\n",
      "83m8maybyg-sagemaker-local  |       proxy_read_timeout 60s;\n",
      "83m8maybyg-sagemaker-local  |       proxy_pass http://gunicorn;\n",
      "83m8maybyg-sagemaker-local  |     }\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  |     location / {\n",
      "83m8maybyg-sagemaker-local  |       return 404 \"{}\";\n",
      "83m8maybyg-sagemaker-local  |     }\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  |   }\n",
      "83m8maybyg-sagemaker-local  | }\n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  | \n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] Module inference does not provide a setup.py. \n",
      "83m8maybyg-sagemaker-local  | Generating setup.py\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] Generating setup.cfg\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] Generating MANIFEST.in\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:33:INFO] Installing module with the following command:\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/bin/python3 -m pip install . \n",
      "83m8maybyg-sagemaker-local  | Processing /opt/ml/code\n",
      "83m8maybyg-sagemaker-local  |   Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "83m8maybyg-sagemaker-local  | \u001b[?25hBuilding wheels for collected packages: inference\n",
      "83m8maybyg-sagemaker-local  |   Building wheel for inference (setup.py) ... \u001b[?25ldone\n",
      "83m8maybyg-sagemaker-local  | \u001b[?25h  Created wheel for inference: filename=inference-1.0.0-py2.py3-none-any.whl size=15714 sha256=bbd36970aae215d165e4a91464f1359c7884117e60e6ef3914d05c0c0d8c2424\n",
      "83m8maybyg-sagemaker-local  |   Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-usvo7m6q/wheels/f3/75/57/158162e9eab7af12b5c338c279b3a81f103b89d74eeb911c00\n",
      "83m8maybyg-sagemaker-local  | Successfully built inference\n",
      "83m8maybyg-sagemaker-local  | Installing collected packages: inference\n",
      "83m8maybyg-sagemaker-local  | Successfully installed inference-1.0.0\n",
      "83m8maybyg-sagemaker-local  | \u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "83m8maybyg-sagemaker-local  | \u001b[0m[2024-01-10 09:02:34 +0000] [44] [INFO] Starting gunicorn 19.10.0\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:34 +0000] [44] [INFO] Listening at: unix:/tmp/gunicorn.sock (44)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:34 +0000] [44] [INFO] Using worker: gevent\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/os.py:1023: RuntimeWarning: line buffering (buffering=1) isn't supported in binary mode, the default buffer size will be used\n",
      "83m8maybyg-sagemaker-local  |   return io.open(fd, *args, **kwargs)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:34 +0000] [46] [INFO] Booting worker with pid: 46\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:34 +0000] [47] [INFO] Booting worker with pid: 47\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:34 +0000] [48] [INFO] Booting worker with pid: 48\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:35 +0000] [49] [INFO] Booting worker with pid: 49\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:35 +0000] [50] [INFO] Booting worker with pid: 50\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:35 +0000] [51] [INFO] Booting worker with pid: 51\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:35 +0000] [52] [INFO] Booting worker with pid: 52\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10 09:02:35 +0000] [53] [INFO] Booting worker with pid: 53\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   from pandas import MultiIndex, Int64Index\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Checking if serving container is up, attempt: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | 127.0.0.1 - - [10/Jan/2024:09:02:36 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"python-urllib3/1.26.18\"\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | 127.0.0.1 - - [10/Jan/2024:09:02:36 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"python-urllib3/1.26.18\"\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:36:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:37:INFO] No GPUs detected (normal if no gpus installed)\n",
      "83m8maybyg-sagemaker-local  | /miniconda3/lib/python3.8/site-packages/xgboost/data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "83m8maybyg-sagemaker-local  |   elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:37:INFO] Successfully completed transform job!\n",
      "83m8maybyg-sagemaker-local  | 127.0.0.1 - - [10/Jan/2024:09:02:37 +0000] \"POST /invocations HTTP/1.1\" 200 145 \"-\" \"python-urllib3/1.26.18\"\n",
      "83m8maybyg-sagemaker-local  | [2024-01-10:09:02:37:INFO] No GPUs detected (normal if no gpus installed)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.local.entities:Pipeline step 'AbaloneTransform' SUCCEEDED.\n",
      "INFO:sagemaker.local.entities:Pipeline execution 47a33ee7-18e9-4ec1-9bc7-0742c8ae57c1 SUCCEEDED\n"
     ]
    }
   ],
   "source": [
    "execution = pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lets wait if executed remotely\n",
    "if not run_locally:\n",
    "    execution.wait(delay=60, max_attempts=60)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Get the step outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PipelineExecutionSteps': [{'EndTime': 1704877342.319331,\n",
       "   'Metadata': {'ProcessingJob': {'Arn': 'AbaloneProcess-1704875001-f6fa'}},\n",
       "   'StartTime': 1704875001.916894,\n",
       "   'StepName': 'AbaloneProcess',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1704877347.690689,\n",
       "   'Metadata': {'TrainingJob': {'Arn': 'AbaloneTrain-1704877342-477e'}},\n",
       "   'StartTime': 1704877342.320386,\n",
       "   'StepName': 'AbaloneTrain',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1704877349.736499,\n",
       "   'Metadata': {'ProcessingJob': {'Arn': 'AbaloneEval-1704877347-d228'}},\n",
       "   'StartTime': 1704877347.691574,\n",
       "   'StepName': 'AbaloneEval',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1704877349.796342,\n",
       "   'Metadata': {'Condition': {'Outcome': True}},\n",
       "   'StartTime': 1704877349.737458,\n",
       "   'StepName': 'AbaloneMSECond',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1704877351.624312,\n",
       "   'Metadata': {'TrainingJob': {'Arn': 'AbaloneCreateModel-RepackModel-0-1704877349-6fd9'}},\n",
       "   'StartTime': 1704877349.797239,\n",
       "   'StepDescription': 'Used to repack a model with customer scripts for a register/create model step',\n",
       "   'StepName': 'AbaloneCreateModel-RepackModel-0',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1704877351.625244,\n",
       "   'Metadata': {'Model': {'Arn': 'AbaloneCreateModel-CreateModel-1704877351-51f7'}},\n",
       "   'StartTime': 1704877351.625115,\n",
       "   'StepName': 'AbaloneCreateModel-CreateModel',\n",
       "   'StepStatus': 'Succeeded'},\n",
       "  {'EndTime': 1704877357.420045,\n",
       "   'Metadata': {'TransformJob': {'Arn': 'AbaloneTransform-1704877351-9bb8'}},\n",
       "   'StartTime': 1704877351.626143,\n",
       "   'StepName': 'AbaloneTransform',\n",
       "   'StepStatus': 'Succeeded'}]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = execution.list_steps()\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-626723862963/LocalModePipeline/47a33ee7-18e9-4ec1-9bc7-0742c8ae57c1/AbaloneProcess/output/train\n",
      "s3://sagemaker-us-east-1-626723862963/LocalModePipeline/47a33ee7-18e9-4ec1-9bc7-0742c8ae57c1/AbaloneProcess/output/validation\n",
      "s3://sagemaker-us-east-1-626723862963/LocalModePipeline/47a33ee7-18e9-4ec1-9bc7-0742c8ae57c1/AbaloneProcess/output/test\n"
     ]
    }
   ],
   "source": [
    "# Get output files from processing job\n",
    "processing_job_name = steps[\"PipelineExecutionSteps\"][0][\"Metadata\"][\"ProcessingJob\"][\"Arn\"]\n",
    "outputs = pipeline_session.sagemaker_client.describe_processing_job(\n",
    "    ProcessingJobName=processing_job_name\n",
    ")[\"ProcessingOutputConfig\"][\"Outputs\"]\n",
    "for key in outputs:\n",
    "    print(outputs[key][\"S3Output\"][\"S3Uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model location :  s3://sagemaker-us-east-1-626723862963/sm-pipelines-local-mode-example/model/AbaloneTrain-1704877342-477e/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "# Get output from training job\n",
    "\n",
    "training_job_name = steps[\"PipelineExecutionSteps\"][1][\"Metadata\"][\"TrainingJob\"][\"Arn\"]\n",
    "outputs = pipeline_session.sagemaker_client.describe_training_job(\n",
    "    TrainingJobName=training_job_name\n",
    ")\n",
    "print(\"Model location : \", outputs[\"ModelArtifacts\"][\"S3ModelArtifacts\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-626723862963/LocalModePipeline/47a33ee7-18e9-4ec1-9bc7-0742c8ae57c1/AbaloneEval/output/evaluation\n"
     ]
    }
   ],
   "source": [
    "# Get output from model evaluation step (processing job)\n",
    "\n",
    "processing_job_name = steps[\"PipelineExecutionSteps\"][2][\"Metadata\"][\"ProcessingJob\"][\"Arn\"]\n",
    "outputs = pipeline_session.sagemaker_client.describe_processing_job(\n",
    "    ProcessingJobName=processing_job_name\n",
    ")[\"ProcessingOutputConfig\"][\"Outputs\"]\n",
    "for key in outputs:\n",
    "    print(outputs[key][\"S3Output\"][\"S3Uri\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Get output of ModelStep\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mjson\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model_name \u001b[39m=\u001b[39m steps[\u001b[39m\"\u001b[39;49m\u001b[39mPipelineExecutionSteps\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mMetadata\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39;49m\u001b[39mModel\u001b[39;49m\u001b[39m\"\u001b[39;49m][\u001b[39m\"\u001b[39m\u001b[39mArn\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m      5\u001b[0m outputs \u001b[39m=\u001b[39m pipeline_session\u001b[39m.\u001b[39msagemaker_client\u001b[39m.\u001b[39mdescribe_model(ModelName\u001b[39m=\u001b[39mmodel_name)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(outputs)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Model'"
     ]
    }
   ],
   "source": [
    "# Get output of ModelStep\n",
    "import json\n",
    "\n",
    "model_name = steps[\"PipelineExecutionSteps\"][-1][\"Metadata\"][\"Model\"][\"Arn\"]\n",
    "outputs = pipeline_session.sagemaker_client.describe_model(ModelName=model_name)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get output from the TransformStep\n",
    "\n",
    "transform_job_name = steps[\"PipelineExecutionSteps\"][4][\"Metadata\"][\"TransformJob\"][\"Arn\"]\n",
    "outputs = pipeline_session.sagemaker_client.describe_transform_job(\n",
    "    TransformJobName=transform_job_name\n",
    ")\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) After a Pipeline Step completes, you can view the CloudWatch Log output \n",
    "\n",
    "Using SageMaker Studio and navigating to the Pipelines components, find the specific execution that just completed. Under the 'Graph' tab on the left panel, select a particular step, like Training (AbaloneTrain in this example), then click the 'Logs' tab on the right panel, and click the 'view logs in CloudWatch console' link. This will open a new tab/window showing the log output from the Training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get logs for each step of the pipeline and print them.\n",
    "import boto3\n",
    "\n",
    "if not run_locally:        \n",
    "    client = boto3.client('logs')\n",
    "    \n",
    "    steps_stream_prefixes = [ (f'/aws/sagemaker/{key}s',val['Arn'].split(\"/\")[-1]) for step in steps for key,val in step[\"Metadata\"].items() if 'Arn' in val and \"Model\" not in key]\n",
    "    group_streams = []\n",
    "    for group_name, stream_prefix in steps_stream_prefixes:\n",
    "        logs = client.describe_log_streams(logGroupName=group_name, logStreamNamePrefix=stream_prefix)\n",
    "        for item in logs[\"logStreams\"]:\n",
    "            group_streams.append((group_name,item['logStreamName']))\n",
    "    \n",
    "    for group_name, stream in group_streams:\n",
    "        logs_batch = client.get_log_events(logGroupName=group_name, logStreamName=stream)\n",
    "        for event in logs_batch['events']:\n",
    "            event.update({'group': group_name, 'stream':stream })\n",
    "            print(event)\n",
    "        while 'nextToken' in logs_batch:\n",
    "            logs_batch = client.get_log_events(logGroupName=group_name, logStreamName=stream, nextToken=logs_batch['nextToken'])\n",
    "            for event in logs_batch['events']:\n",
    "                event.update({'group': group_name, 'stream':stream })\n",
    "                print(event)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
